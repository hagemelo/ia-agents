{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2653efc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hagem\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import os\n",
        "import requests\n",
        "import gradio as gr\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "import asyncio\n",
        "import time\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d44e9dc0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'model': 'gpt-4o-mini', 'agent': <openai.OpenAI at 0x24abf9183d0>},\n",
              " {'model': 'gpt-5-mini', 'agent': <openai.OpenAI at 0x24abf9186d0>},\n",
              " {'model': 'gemini-2.5-flash', 'agent': <openai.OpenAI at 0x24abf918460>}]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Criando os agentes e os modelos que serão utilizados\n",
        "agents = []\n",
        "\n",
        "agentsGpt4oMini = {\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"agent\": OpenAI()\n",
        "}\n",
        "\n",
        "agents.append(agentsGpt4oMini)\n",
        "\n",
        "agentsGpt5Mini = {\n",
        "    \"model\": \"gpt-5-mini\",\n",
        "    \"agent\": OpenAI()\n",
        "}\n",
        "\n",
        "agents.append(agentsGpt5Mini)\n",
        "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "agentsGemini25Flash = {\n",
        "    \"model\": \"gemini-2.5-flash\",\n",
        "    \"agent\": OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\" )\n",
        "}\n",
        "agents.append(agentsGemini25Flash)\n",
        "        \n",
        "agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "53d3a9b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregando recussos e as principais classes\n",
        "with open(\"recursos/every-money-readme.md\", \"r\", encoding=\"utf-8\") as f:\n",
        "    everyMoneyReadme = f.read()\n",
        "\n",
        "with open(\"recursos/criticidade.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    criticidade = f.read()\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    is_acceptable: bool\n",
        "    feedback: str\n",
        "\n",
        "class Risco(BaseModel):\n",
        "    nome: str\n",
        "    criticidade: str\n",
        "    descricao: str\n",
        "    dano_causado: str\n",
        "    probabilidade: str\n",
        "    impacto: str\n",
        "\n",
        "class Riscos(BaseModel):\n",
        "    riscos: List[Risco]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1d8c7c13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# instrução para os agente que irao criar os riscos\n",
        "build_riscos_system_prompt = f\"\"\"Você é um especialista em análise de riscos e deve analisar o seguinte projeto: {everyMoneyReadme}\n",
        "\n",
        "Classifique os riscos de acordo com a criticidade: {criticidade}\n",
        "\n",
        "Apresente pelo menos 3 riscos, classificados conforme a criticidade.\n",
        "\n",
        "Não seja muito verboso na descrição dos riscos, sendo sucinto e direto.\n",
        "\n",
        "Deve se atentar para as funcionalidades do projeto, e não apenas as tecnologias utilizadas.\n",
        "\n",
        "O resultado deve ser apresentado em formato JSON, seguindo o modelo abaixo:\n",
        "{{\n",
        "    \"Riscos\": [\n",
        "        {{\n",
        "            \"nome\": \"Nome do risco\",\n",
        "            \"criticidade\": \"Criticidade do risco\",\n",
        "            \"descricao\": \"Descrição do risco\",\n",
        "            \"dano_causado\": \"Dano causado pelo risco\",\n",
        "            \"probabilidade\": \"Probabilidade de ocorrência do risco, pode ser baixa, média ou alta\",\n",
        "            \"impacto\": \"Impacto do risco, pode ser baixo, médio ou alto\"\n",
        "        }}\n",
        "    ]\n",
        "}}\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0255ed82",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Construindo os tool para o avaliador\n",
        "\n",
        "def mostrar_feedback_positivo(nome, descricao):\n",
        "    print(f\"O risco {nome} foi aceito, descrição: {descricao}\")\n",
        "    return {\"recorded\": \"ok\"}\n",
        "\n",
        "record_mostrar_feedback_positivo_json = {\n",
        "    \"name\": \"mostrar_feedback_positivo\",\n",
        "    \"description\": \"Utilize esta função para mostrar o feedback positivo do risco avaliado\",\n",
        "    \"strict\": True,\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "                \"nome\": {\"type\": \"string\"},\n",
        "                \"descricao\": {\"type\": \"string\"},\n",
        "                },\n",
        "        \"required\": [\"nome\", \"descricao\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}\n",
        "    \n",
        "def mostrar_feedback_negativo(nome, descricao):\n",
        "    print(f\"O risco {nome} foi rejeitado, descrição: {descricao}\")\n",
        "    return {\"recorded\": \"ok\"}\n",
        "\n",
        "record_mostrar_feedback_negativo_json = {\n",
        "    \"name\": \"mostrar_feedback_negativo\",\n",
        "    \"description\": \"Utilize esta função para mostrar o feedback negativo do risco avaliado\",\n",
        "    \"strict\": True,\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "                \"nome\": {\"type\": \"string\"},\n",
        "                \"descricao\": {\"type\": \"string\"},\n",
        "                },\n",
        "        \"required\": [\"nome\", \"descricao\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}\n",
        "\n",
        "# Mapeamento de nomes de funções para as funções Python\n",
        "tool_functions = {\n",
        "    \"mostrar_feedback_positivo\": mostrar_feedback_positivo,\n",
        "    \"mostrar_feedback_negativo\": mostrar_feedback_negativo\n",
        "}\n",
        "\n",
        "tools = [{\"type\": \"function\", \"function\": record_mostrar_feedback_positivo_json},\n",
        "        {\"type\": \"function\", \"function\": record_mostrar_feedback_negativo_json}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b93565d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construindo o avaliador de riscos\n",
        "agentsGpt5Nano = OpenAI(\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "evaluator_system_prompt = \"Você é um avaliador de riscos e deve avaliar os riscos apresentados pelo analista de riscos.\"\\\n",
        "    \"Avalie se os riscos estão de acordo com o projeto e se são relevantes.\"\\\n",
        "    \"Se houver riscos que não estão de acordo com a descrição, avalie se eles são relevantes para o projeto.\"\\\n",
        "    \"Se houver riscos que não estão de acordo com o dano causado, avalie se eles são relevantes para o projeto.\"\\\n",
        "    \"Se houver riscos que não estão de acordo com o impacto, avalie se eles são relevantes para o projeto.\"\\\n",
        "    \"Ao final sua resposta deve ser o risco isacceptable e o feedback para o analista de riscos.\" \n",
        "    \n",
        "\n",
        "def evaluator_user_prompt(reply, riscos, history):\n",
        "    user_prompt = f\"Temos aqui o histórico de avalição do risco: \\n\\n{history}\\n\\n\"\n",
        "    user_prompt += f\"Aqui temos o risco apresentado pelo analista de riscos: \\n\\n{riscos}\\n\\n\"\n",
        "    user_prompt += f\"Aqui temos a resposta do avaliador: \\n\\n{reply}\\n\\n\"\n",
        "    user_prompt += \"Adicionalmente, use a função mostrar_feedback_positivo em tools quando is_acceptable for true.\"\n",
        "    user_prompt += \"Adicionalmente, use a função mostrar_feedback_negativo em tools quando is_acceptable for false.\"\n",
        "    user_prompt += \"Por favor avalie a resposta, respondendo se é aceitável e seu feedback. seguindo o modelo abaixo: \\n\\n\"\n",
        "    user_prompt += \"{{ \\n\\n\"\n",
        "    user_prompt += \"    \\\"is_acceptable\\\": true, \\n\\n\"\n",
        "    user_prompt += \"    \\\"feedback\\\": \\\"Feedback do avaliador\\\" \\n\\n\"\n",
        "    user_prompt += \"}}\"\n",
        "    return user_prompt\n",
        "\n",
        "\n",
        "async def evaluate(reply, riscos, history) -> Evaluation:\n",
        "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, riscos, history)}]\n",
        "    \n",
        "    # Primeira chamada - pode retornar tool_calls ou o objeto parseado\n",
        "    response = agentsGpt5Nano.beta.chat.completions.parse(model=\"gpt-5-nano\", messages=messages, response_format=Evaluation, tools=tools)\n",
        "    \n",
        "    finish_reason = response.choices[0].finish_reason\n",
        "  \n",
        "    # Se a resposta contém tool calls, processar as funções\n",
        "    if finish_reason == \"tool_calls\":\n",
        "        message = response.choices[0].message\n",
        "        \n",
        "        # Converter tool_calls para o formato de dicionário esperado pela API\n",
        "        tool_calls_dict = []\n",
        "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "            for tc in message.tool_calls:\n",
        "                tool_calls_dict.append({\n",
        "                    \"id\": tc.id,\n",
        "                    \"type\": \"function\",\n",
        "                    \"function\": {\n",
        "                        \"name\": tc.function.name,\n",
        "                        \"arguments\": tc.function.arguments\n",
        "                    }\n",
        "                })\n",
        "        \n",
        "        messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": message.content if message.content else None,\n",
        "            \"tool_calls\": tool_calls_dict\n",
        "        })\n",
        "        \n",
        "        # Processar cada tool call\n",
        "        tool_responses = []\n",
        "        if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "            for tool_call in message.tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "                \n",
        "                # Executar a função correspondente\n",
        "                if function_name in tool_functions:\n",
        "                    function_result = tool_functions[function_name](**function_args)\n",
        "                    tool_responses.append({\n",
        "                        \"tool_call_id\": tool_call.id,\n",
        "                        \"role\": \"tool\",\n",
        "                        \"name\": function_name,\n",
        "                        \"content\": json.dumps(function_result)\n",
        "                    })\n",
        "        \n",
        "        # Adicionar as respostas das tools às mensagens\n",
        "        messages.extend(tool_responses)\n",
        "        \n",
        "        # Segunda chamada para obter o objeto Evaluation parseado\n",
        "        response = agentsGpt5Nano.beta.chat.completions.parse(model=\"gpt-5-nano\", messages=messages, response_format=Evaluation, tools=tools)\n",
        "\n",
        "    \n",
        "    parsed = response.choices[0].message.parsed\n",
        "    if parsed is None:\n",
        "        raise ValueError(\"Não foi possível obter o objeto Evaluation parseado\")\n",
        "    \n",
        "    return parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0ad1672f",
      "metadata": {},
      "outputs": [],
      "source": [
        "async def acionar_analista_de_riscos(message, agent) -> Riscos:\n",
        "    model0 = agent['model']\n",
        "    print(f\"Gerando riscos com o modelo {model0}\")\n",
        "    agentModel = agent['agent']\n",
        "    messages = [{\"role\": \"system\", \"content\": build_riscos_system_prompt}] + message\n",
        "    response = agentModel.chat.completions.parse(model = model0, messages=messages, response_format=Riscos)\n",
        "    return response.choices[0].message.parsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ce2588",
      "metadata": {},
      "outputs": [],
      "source": [
        "NUMERO_MAXIMO_DE_REAVALIACOES = 1\n",
        "async def gerar_riscos(agent) -> Riscos:\n",
        "    try:\n",
        "        riscos_criados = []\n",
        "        messages = [{\"role\": \"user\", \"content\": \"Gerar riscos para o projeto EveryMoney\"}]\n",
        "        riscos = await acionar_analista_de_riscos(messages, agent)\n",
        "        valor_corrente = 0\n",
        "        resposta_avaliador = \"\"\n",
        "        while valor_corrente < NUMERO_MAXIMO_DE_REAVALIACOES:\n",
        "            evaluation = await evaluate(resposta_avaliador, riscos, messages)\n",
        "            if evaluation.is_acceptable:\n",
        "                print(\"Passed evaluation - returning reply\")\n",
        "                riscos_criados.append(riscos)\n",
        "            else:\n",
        "                print(\"Failed evaluation - retrying\")\n",
        "                print(evaluation.feedback)\n",
        "                resposta_avaliador += evaluation.feedback\n",
        "\n",
        "            valor_corrente += 1\n",
        "        return riscos_criados\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar riscos com o agente {agent['model']}: {e}\")\n",
        "\n",
        "\n",
        "def serializador_customizado(obj):\n",
        "    if hasattr(obj, '__dict__'):\n",
        "        return obj.__dict__\n",
        "    return str(obj)     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "29d2434f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def imprimir_riscos(resultados):\n",
        "    print(f\"Quantidade de riscos: {len(resultados)}\")\n",
        "    for resultado in resultados:\n",
        "       print(json.dumps(resultado, indent=4, ensure_ascii=False, default=serializador_customizado))\n",
        "\n",
        "\n",
        "async def main():\n",
        "    print(\"--- Iniciando Promise.all (asyncio.gather) ---\")\n",
        "    inicio = time.perf_counter()\n",
        "    execucoes_agentes = []\n",
        "    for agent in agents:\n",
        "        execucoes_agentes.append(gerar_riscos(agent))\n",
        "\n",
        "    resultados = await asyncio.gather(*execucoes_agentes)\n",
        "    imprimir_riscos(resultados)\n",
        "    fim = time.perf_counter()\n",
        "    print(f\"Tempo total de execução: {fim - inicio:.2f} segundos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "8f5c30ff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Iniciando Promise.all (asyncio.gather) ---\n",
            "Gerando riscos com o modelo gpt-4o-mini\n",
            "Finish reason: tool_calls\n",
            "O risco Vazamento de Dados do Usuário foi aceito, descrição: Possibilidade de dados sensíveis do usuário (como senhas ou informações financeiras) serem expostos devido a falhas de segurança.\n",
            "O risco Erros na Lógica de Cálculo de Saldos foi aceito, descrição: Possibilidade de erros na implementação das funções que calculam saldos realizados e previstos, levando a informações financeiras incorretas.\n",
            "O risco Interrupção na Disponibilidade do Serviço foi aceito, descrição: Risco de downtime do sistema devido a falhas na infraestrutura ou problemas de desempenho na aplicação.\n",
            "Finish reason após tool calls: stop\n",
            "{\n",
            "    \"is_acceptable\": true,\n",
            "    \"feedback\": \"Riscos apresentados estão em linha com o objetivo do projeto EveryMoney (proteção de dados, exatidão financeira e disponibilidade). São relevantes e merecem tratamento. Observações:\\n- Vazamento de Dados do Usuário: alto dano potencial, probabilidade média. Recomendações de mitigação: criptografia em repouso e trânsito, gestão de identidade e acesso, autenticação multifator, monitoramento de logs, testes de penetração, plano de resposta a incidentes, DLP. Identificar responsável e prazos.\\n- Erros na Lógica de Cálculo de Saldos: risco de informações incorretas que impactam decisões financeiras. Recomendações: validações unitárias e de integração, reconciliação de saldos, teste de regressão automatizado, auditoria de trilha, revisão de modelos de cálculo.\\n- Interrupção na Disponibilidade do Serviço: alto impacto, probabilidade baixa. Recomendações: redundância de infraestrutura, alta disponibilidade, failover, monitoramento frequente, plano de continuidade e testes de disaster recovery; definir SLOs/SLIs.\\n\\nSugestões adicionais: atribuir owners para cada risco, registrar controles existentes, estabelecer planos de mitigação com prazos, e alinhar as definições de probabilidade/impacto com a matriz de risco. Vincular cada risco a requisitos legais (ex.: LGPD/PCI-DSS conforme aplicável) e definir indicadores de risco (KRIs) para monitoramento contínuo. Em resumo, risco considerado aceitável desde que haja planos de mitigação, owners e governança claros.\"\n",
            "}\n",
            "Passed evaluation - returning reply\n",
            "Gerando riscos com o modelo gpt-5-mini\n",
            "Finish reason: tool_calls\n",
            "O risco Avaliação de riscos - EveryMoney foi aceito, descrição: Riscos apresentados cobrem áreas críticas relevantes ao domínio financeiro e à plataforma EveryMoney: cálculo incorreto de saldos, falhas de autorização (IDOR), gerenciamento de credenciais/JWT, perda de dados no PostgreSQL, vulnerabilidades de frontend e notificações de orçamento. As descrições, dano causado, probabilidade e impacto estão coerentes com o potencial de dano. Recomenda-se manter e monitorar com planos de mitigação específicos (transações atômicas, controles de acesso, políticas de senha, revogação de tokens, backups/restore, validação de entradas, monitoramento/alertas).\n",
            "Finish reason após tool calls: tool_calls\n",
            "Erro ao gerar riscos com o agente gpt-5-mini: Não foi possível obter o objeto Evaluation parseado\n",
            "Gerando riscos com o modelo gemini-2.5-flash\n",
            "Finish reason: tool_calls\n",
            "O risco Avaliação Geral de Riscos - EveryMoney foi aceito, descrição: Riscos apresentados são relevantes para o domínio financeiro do projeto: Inconsistência nos Cálculos Financeiros, Falha na Segurança da Autenticação/Autorização e Perda ou Corrupção de Dados Financeiros. Os níveis de criticidade e impacto são coerentes com as consequências, especialmente considerando danos como perda de confiança, fraudes e indisponibilidade de dados. A avaliação confirma alinhamento com o escopo; recomenda-se manter esses riscos no backlog e aplicar mitigação como testes de cálculo, validação de lógica de transação, controles de acesso, criptografia, MFA, backups e monitoramento de integridade.\n",
            "Finish reason após tool calls: tool_calls\n",
            "Erro ao gerar riscos com o agente gemini-2.5-flash: Não foi possível obter o objeto Evaluation parseado\n",
            "Quantidade de riscos: 3\n",
            "[\n",
            "    {\n",
            "        \"riscos\": [\n",
            "            {\n",
            "                \"nome\": \"Vazamento de Dados do Usuário\",\n",
            "                \"criticidade\": \"Alta\",\n",
            "                \"descricao\": \"Possibilidade de dados sensíveis do usuário (como senhas ou informações financeiras) serem expostos devido a falhas de segurança.\",\n",
            "                \"dano_causado\": \"Danos à reputação da empresa e perda de confiança por parte dos usuários.\",\n",
            "                \"probabilidade\": \"Média\",\n",
            "                \"impacto\": \"Alto\"\n",
            "            },\n",
            "            {\n",
            "                \"nome\": \"Erros na Lógica de Cálculo de Saldos\",\n",
            "                \"criticidade\": \"Média\",\n",
            "                \"descricao\": \"Possibilidade de erros na implementação das funções que calculam saldos realizados e previstos, levando a informações financeiras incorretas.\",\n",
            "                \"dano_causado\": \"Informações financeiras imprecisas que podem afetar as decisões dos usuários.\",\n",
            "                \"probabilidade\": \"Média\",\n",
            "                \"impacto\": \"Médio\"\n",
            "            },\n",
            "            {\n",
            "                \"nome\": \"Interrupção na Disponibilidade do Serviço\",\n",
            "                \"criticidade\": \"Alta\",\n",
            "                \"descricao\": \"Risco de downtime do sistema devido a falhas na infraestrutura ou problemas de desempenho na aplicação.\",\n",
            "                \"dano_causado\": \"Perda de usuários e diminuição da confiança no serviço.\",\n",
            "                \"probabilidade\": \"Baixa\",\n",
            "                \"impacto\": \"Alto\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n",
            "null\n",
            "null\n",
            "Tempo total de execução: 151.16 segundos\n"
          ]
        }
      ],
      "source": [
        "\n",
        "await main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
